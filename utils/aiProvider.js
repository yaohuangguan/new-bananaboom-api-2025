// utils/aiProvider.js
const { GoogleGenAI } = require("@google/genai");

// 1. åŸºç¡€é…ç½®
if (!process.env.GEMINI_API_KEY) {
  throw new Error("âŒ [Fatal] ç¼ºå°‘ç¯å¢ƒå˜é‡ GEMINI_API_KEY");
}

// åˆå§‹åŒ–å®¢æˆ·ç«¯
const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });

// ç”Ÿäº§çº§é…ç½®å¸¸é‡
const CONFIG = {
  // é¦–é€‰æ¨¡å‹ (ä½ æŒ‡å®šçš„)
  PRIMARY_MODEL: "gemini-3-flash-preview", 
  // å¤‡èƒæ¨¡å‹ (å¦‚æœé¦–é€‰æŒ‚äº†ï¼Œè‡ªåŠ¨åˆ‡åˆ°è¿™ä¸ªæœ€ç¨³çš„)
  FALLBACK_MODEL: "gemini-2.0-flash-exp", 
  // æœ€å¤§é‡è¯•æ¬¡æ•°
  MAX_RETRIES: 2,
  // è¶…æ—¶æ—¶é—´ (æ¯«ç§’)
  TIMEOUT_MS: 15000,
};

/**
 * è¾…åŠ©å‡½æ•°ï¼šæ¸…æ´— AI è¿”å›çš„ JSON å­—ç¬¦ä¸²
 * å»é™¤ ```json ä»£ç å—æ ‡è®°ï¼Œå¤„ç†å¯èƒ½çš„éæ ‡å‡†å­—ç¬¦
 */
function cleanJSONString(text) {
  if (!text) return "{}";
  // 1. å»é™¤ Markdown ä»£ç å—æ ‡è®° (```json ... ```)
  let clean = text.replace(/```json|```/g, "").trim();
  // 2. å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }ï¼Œå»é™¤ä¹‹å¤–çš„åºŸè¯
  const firstOpen = clean.indexOf("{");
  const lastClose = clean.lastIndexOf("}");
  if (firstOpen !== -1 && lastClose !== -1) {
    clean = clean.substring(firstOpen, lastClose + 1);
  }
  return clean;
}

/**
 * è¾…åŠ©å‡½æ•°ï¼šå¸¦è¶…æ—¶çš„ Promise åŒ…è£…å™¨
 */
function withTimeout(promise, ms) {
  return Promise.race([
    promise,
    new Promise((_, reject) =>
      setTimeout(() => reject(new Error("TIMEOUT")), ms)
    ),
  ]);
}

/**
 * æ ¸å¿ƒç”Ÿæˆå‡½æ•° (æ”¯æŒé‡è¯•ã€é™çº§ã€æ¸…æ´—)
 * @param {string} prompt - æç¤ºè¯
 * @param {string} modelName - æŒ‡å®šæ¨¡å‹ (å¯é€‰)
 */
async function generateJSON(prompt, modelName = CONFIG.PRIMARY_MODEL) {
  let currentModel = modelName;
  let attempts = 0;

  while (attempts <= CONFIG.MAX_RETRIES) {
    attempts++;
    console.log(`ğŸ¤– [AI] æ­£åœ¨è¯·æ±‚æ¨¡å‹: ${currentModel} (å°è¯• ${attempts}/${CONFIG.MAX_RETRIES + 1})`);

    try {
      // 1. å‘èµ·è¯·æ±‚ (å¸¦è¶…æ—¶æ§åˆ¶)
      const response = await withTimeout(
        ai.models.generateContent({
          model: currentModel,
          contents: prompt,
          config: { responseMimeType: "application/json" },
        }),
        CONFIG.TIMEOUT_MS
      );

      // 2. è·å–å¹¶æ¸…æ´—æ–‡æœ¬
      // æ–°ç‰ˆ SDK response.text å¯èƒ½æ˜¯ getterï¼Œç›´æ¥è®¿é—®
      const rawText = response.text || JSON.stringify(response);
      const cleanedText = cleanJSONString(rawText);

      // 3. è§£æå¹¶è¿”å›
      return JSON.parse(cleanedText);

    } catch (err) {
      console.error(`âš ï¸ [AI Error] æ¨¡å‹ ${currentModel} æŠ¥é”™:`, err.message);

      // ğŸ›‘ æƒ…å†µ A: è‡´å‘½é”™è¯¯ (404 Not Found / 400 Bad Request)
      // è¯´æ˜æ¨¡å‹åå­—ä¸å¯¹ï¼Œæˆ–è€…æ¨¡å‹ä¸å­˜åœ¨ã€‚æ­¤æ—¶é‡è¯•æ²¡ç”¨ï¼Œç›´æ¥é™çº§ï¼
      if (err.message.includes("404") || err.message.includes("not found") || err.message.includes("400")) {
        if (currentModel !== CONFIG.FALLBACK_MODEL) {
          console.warn(`ğŸ”„ [AI Fallback] æ¨¡å‹ ${currentModel} ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹: ${CONFIG.FALLBACK_MODEL}`);
          currentModel = CONFIG.FALLBACK_MODEL;
          attempts = 0; // é‡ç½®é‡è¯•æ¬¡æ•°ç»™å¤‡ç”¨æ¨¡å‹
          continue; // ç«‹å³ç”¨æ–°æ¨¡å‹é‡è¯•
        } else {
           // å¤‡èƒä¹ŸæŒ‚äº†ï¼ŒæŠ›å‡ºé”™è¯¯
           throw new Error("æ‰€æœ‰æ¨¡å‹å‡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œ");
        }
      }

      // ğŸ›‘ æƒ…å†µ B: ä¸´æ—¶é”™è¯¯ (429 Too Many Requests / 503 Overloaded / Timeout)
      // å¯ä»¥é‡è¯•
      const isRetryable = err.message.includes("429") || err.message.includes("503") || err.message === "TIMEOUT";
      
      if (isRetryable && attempts <= CONFIG.MAX_RETRIES) {
        const delay = attempts * 1000; // çº¿æ€§é€€é¿: ç­‰å¾… 1s, 2s...
        console.log(`â³ [AI Retry] é‡åˆ°ä¸´æ—¶é”™è¯¯ï¼Œ${delay}ms åé‡è¯•...`);
        await new Promise((r) => setTimeout(r, delay));
        continue;
      }

      // æ— æ³•ä¿®å¤çš„é”™è¯¯ï¼Œæˆ–è€…é‡è¯•æ¬¡æ•°ç”¨å°½
      // è¿”å›ä¸€ä¸ªä¼˜é›…çš„ç©ºå¯¹è±¡æˆ–é”™è¯¯æ ‡è¯†ï¼Œé¿å…å‰ç«¯ç™½å±
      return { 
        error: "AI_GENERATION_FAILED", 
        message: "å¤§å¨æ­£åœ¨å¿™ï¼Œè¯·ç¨åå†è¯•",
        debug: err.message 
      };
    }
  }
}


/**
 * è¾…åŠ©å‡½æ•°ï¼šæ¸…æ´— Prompt æ ¼å¼
 * ç¡®ä¿å‘ç»™ SDK çš„æ°¸è¿œæ˜¯æ ‡å‡†æ•°ç»„ç»“æ„ï¼Œé˜²æ­¢æŠ¥é”™
 */
function formatInput(input) {
  // å¦‚æœå·²ç»æ˜¯æ•°ç»„ï¼ˆæ¯”å¦‚ä½ ä»¥ååšåŸç”Ÿ Chatï¼‰ï¼Œç›´æ¥è¿”å›
  if (Array.isArray(input)) return input;
  
  // å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆGod Mode æ‹¼å‡‘çš„å¤§æ–‡æœ¬ï¼‰ï¼ŒåŒ…è£…æˆ User Message
  return [
    {
      role: "user",
      parts: [{ text: String(input) }] // å¼ºåˆ¶è½¬ string é˜²æ­¢ä¼ è¿›æ¥ undefined
    }
  ];
}

/**
 * ğŸŒŠ æµå¼ç”Ÿæˆå·¥å…· (Final Version)
 * @param {string | Array} promptInput - æç¤ºè¯æˆ–å¯¹è¯æ•°ç»„
 * @returns {Promise<AsyncGenerator>} - è¿”å›å¯è¿­ä»£çš„æµå¯¹è±¡
 */
async function generateStream(promptInput) {
  let currentModel = CONFIG.PRIMARY_MODEL;

  // æ ¼å¼åŒ–è¾“å…¥ï¼šè™½ç„¶æ–‡æ¡£è¯´æ”¯æŒ stringï¼Œä½†åŒ…è£…æˆå¯¹è±¡æœ€ç¨³å¦¥
  const formattedContents = typeof promptInput === 'string'
    ? { role: 'user', parts: [{ text: promptInput }] }
    : promptInput; // å¦‚æœå·²ç»æ˜¯æ•°ç»„ç›´æ¥ç”¨

  try {
    console.log(`ğŸŒŠ [AI Stream] Attempting model: ${currentModel}`);

    // ğŸ”¥ è°ƒç”¨æ–°ç‰ˆ SDK
    // æ³¨æ„ï¼šgenerateContentStream è¿”å›çš„ response æœ¬èº«å°±æ˜¯ async iterable
    const response = await ai.models.generateContentStream({
      model: currentModel,
      contents: formattedContents,
      config: {
        // å¯é€‰é…ç½®
        // maxOutputTokens: 8192,
      }
    });

    // è¿™é‡Œç›´æ¥è¿”å› response å¯¹è±¡å³å¯ï¼Œå› ä¸ºå®ƒå®ç°äº† [Symbol.asyncIterator]
    return response;

  } catch (err) {
    console.error(`âš ï¸ [AI Stream Error] ${currentModel} failed:`, err.message);

    // --- è‡ªåŠ¨é™çº§é€»è¾‘ ---
    if (currentModel !== CONFIG.FALLBACK_MODEL) {
      console.warn(`ğŸ”„ [AI Stream Fallback] Switching to ${CONFIG.FALLBACK_MODEL}...`);
      try {
        const fallbackResponse = await ai.models.generateContentStream({
          model: CONFIG.FALLBACK_MODEL,
          contents: formattedContents,
        });
        return fallbackResponse;
      } catch (fallbackErr) {
        throw new Error(`AI Stream All Failed: ${fallbackErr.message}`);
      }
    }
    throw err;
  }
}

/**
 * ğŸ§  å¯¹å¤–æš´éœ²çš„ Agent æµå¼ç”Ÿæˆå™¨
 * åŒ…å«äº†è‡ªåŠ¨é™çº§é€»è¾‘ï¼šå¦‚æœ 3.0 æŒ‚äº†ï¼Œè‡ªåŠ¨åˆ‡ 2.0
 */
async function* createAgentStream(params) {
  let currentModel = CONFIG.PRIMARY_MODEL;

  try {
    console.log(`ğŸŒŠ [Agent Stream] Attempting with ${currentModel}...`);
    // å°è¯•ä½¿ç”¨ä¸»æ¨¡å‹è¿è¡Œ
    yield* _runAgentLoop(currentModel, params);

  } catch (err) {
    console.warn(`âš ï¸ [Agent Warning] ${currentModel} failed: ${err.message}`);
    
    // å¦‚æœä¸»æ¨¡å‹å¤±è´¥ï¼Œä¸”å¤‡èƒæ¨¡å‹ä¸ä¸€æ ·ï¼Œåˆ™åˆ‡æ¢
    if (currentModel !== CONFIG.FALLBACK_MODEL) {
      console.log(`ğŸ”„ [Agent Fallback] Switching to ${CONFIG.FALLBACK_MODEL}...`);
      try {
        // å°è¯•ä½¿ç”¨å¤‡èƒæ¨¡å‹è¿è¡Œ
        yield* _runAgentLoop(CONFIG.FALLBACK_MODEL, params);
      } catch (fallbackErr) {
        console.error("âŒ [Agent Error] All models failed.");
        throw new Error(`Agent failed on both models: ${fallbackErr.message}`);
      }
    } else {
      throw err;
    }
  }
}

/**
 * ğŸ•µï¸ å†…éƒ¨æ ¸å¿ƒé€»è¾‘ï¼šAgent å¾ªç¯
 * è´Ÿè´£ï¼šå¯¹è¯ -> ç›‘å¬æµ -> æ‹¦æˆªå·¥å…·è°ƒç”¨ -> æ‰§è¡Œå·¥å…· -> äºŒæ¬¡ç”Ÿæˆ
 */
async function* _runAgentLoop(modelName, { systemInstruction, history, prompt, toolsSchema, functionsMap }) {
  
  // 1. åˆå§‹åŒ–æ¨¡å‹å®ä¾‹
  const model = ai.getGenerativeModel({
    model: modelName,
    systemInstruction: systemInstruction,
    tools: toolsSchema, // æ³¨å…¥å·¥å…·å®šä¹‰
    config: {
       // é˜²æ­¢æ­»å¾ªç¯æˆ–ç”Ÿæˆè¿‡é•¿
       maxOutputTokens: 8192, 
    }
  });

  // 2. å¯åŠ¨å¯¹è¯ä¼šè¯
  const chat = model.startChat({ history });

  // 3. å‘é€ç”¨æˆ· prompt (å¼€å¯ç¬¬ä¸€æ®µæµ)
  const result = await chat.sendMessageStream([{ role: 'user', parts: [{ text: prompt }] }]);

  // ä¸´æ—¶çŠ¶æ€
  let functionCallFound = false;
  let functionCallsToExecute = [];

  // =================================================
  // ç¬¬ä¸€é˜¶æ®µï¼šç›‘å¬ AI çš„åˆæ­¥ååº”
  // =================================================
  for await (const chunk of result.stream) {
    // A. æ£€æŸ¥ SDK æ˜¯å¦è§£æå‡ºäº†å‡½æ•°è°ƒç”¨
    const calls = chunk.functionCalls();
    
    if (calls && calls.length > 0) {
      functionCallFound = true;
      functionCallsToExecute.push(...calls);
      // æ³¨æ„ï¼šå½“å‘ç°å‡½æ•°è°ƒç”¨æ—¶ï¼Œæˆ‘ä»¬ä¸ yield æ–‡æœ¬ï¼Œå› ä¸ºæ­¤æ—¶é€šå¸¸æ²¡æœ‰æ–‡æœ¬ï¼Œæˆ–è€…æ–‡æœ¬æ˜¯ä¸­æ–­çš„
      continue; 
    }

    // B. å¦‚æœæ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œè¯´æ˜æ˜¯æ™®é€šèŠå¤©ï¼Œç›´æ¥åå­—
    if (!functionCallFound) {
      const text = chunk.text();
      if (text) yield text;
    }
  }

  // =================================================
  // ç¬¬äºŒé˜¶æ®µï¼šæ‰§è¡Œå·¥å…·å¹¶è·å–æœ€ç»ˆå›å¤ (Agent æ ¸å¿ƒ)
  // =================================================
  if (functionCallFound && functionCallsToExecute.length > 0) {
    
    const functionResponses = [];

    // 1. æ‰§è¡Œæ‰€æœ‰è¢«è¯·æ±‚çš„å‡½æ•°
    for (const call of functionCallsToExecute) {
      const funcName = call.name;
      const args = call.args;
      
      console.log(`ğŸ¤– [Agent Executor] Model: ${modelName} | Calling: ${funcName}`, args);

      let toolResult;
      // åœ¨ä¼ å…¥çš„æ˜ å°„è¡¨ä¸­æŸ¥æ‰¾å‡½æ•°
      if (functionsMap && functionsMap[funcName]) {
        try {
          // ğŸ”¥ æ‰§è¡ŒçœŸå®é€»è¾‘ (è¿™é‡Œçš„å‡½æ•°å·²ç»ç»‘å®šäº† userId)
          toolResult = await functionsMap[funcName](args);
        } catch (e) {
          console.error(`Tool execution error (${funcName}):`, e);
          toolResult = { error: `Execution failed: ${e.message}` };
        }
      } else {
        toolResult = { error: `Function ${funcName} not found on server` };
      }

      // æ„é€  Gemini éœ€è¦çš„ FunctionResponse æ ¼å¼
      functionResponses.push({
        functionResponse: {
          name: funcName,
          response: { content: toolResult } // å¿…é¡»åŒ…åœ¨ content é‡Œ
        }
      });
    }

    // 2. å°†æ‰§è¡Œç»“æœå‘å›ç»™ AI (å¼€å¯ç¬¬äºŒæ®µæµ)
    console.log(`ğŸ“¤ [Agent Output] Sending ${functionResponses.length} tool results back to AI...`);
    
    const result2 = await chat.sendMessageStream([{ role: 'function', parts: functionResponses }]);

    // 3. å°† AI è¯»å®Œæ‰§è¡Œç»“æœåçš„æœ€ç»ˆå›å¤ï¼Œæ¨ç»™å‰ç«¯
    for await (const chunk2 of result2.stream) {
      const text2 = chunk2.text();
      if (text2) yield text2;
    }
  }
}

module.exports = { generateJSON, generateStream, createAgentStream };
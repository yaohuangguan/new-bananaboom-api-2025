// utils/aiProvider.js
import { GoogleGenAI } from '@google/genai';
import { fetch } from 'undici'
import sharp from 'sharp';
// 1. åŸºç¡€é…ç½®
if (!process.env.GEMINI_API_KEY) {
  throw new Error('âŒ [Fatal] ç¼ºå°‘ç¯å¢ƒå˜é‡ GEMINI_API_KEY');
}

const ai = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY
});

// ç”Ÿäº§çº§é…ç½®
const CONFIG = {
  PRIMARY_MODEL: 'gemini-3-flash-preview',
  FALLBACK_MODEL: 'gemini-2.0-flash-exp',
  MAX_RETRIES: 1,
  TIMEOUT_MS: 120000 // 2åˆ†é’Ÿè¶…æ—¶
};

// ==========================================
// 1. å¼ºåŠ›ä¸‹è½½å™¨ (å¸¦è¯¦ç»† Debug)
// ==========================================
const fetchImageAsBase64 = async (url) => {
  const cleanUrl = url.trim();
  console.log(`ğŸ“¥ [Image] å°è¯•ä¸‹è½½: ${cleanUrl.substring(0, 40)}...`);

  try {
    const response = await fetch(cleanUrl, {
      method: 'GET',
      redirect: 'follow', // è·Ÿéšé‡å®šå‘
      headers: {
        // Cloudflare WAF é€šè¡Œè¯ (å…¨å°å†™)
        'x-server-secret': 'orion-x-888',
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
      }
    });

    // ğŸ”¥ æ‰“å°çŠ¶æ€ç ï¼Œè¿™æ˜¯è°ƒè¯• Cloudflare æœ€å…³é”®çš„ä¿¡æ¯
    console.log(`ğŸ“¡ [Image Status] R2 è¿”å›: ${response.status} ${response.statusText}`);

    if (!response.ok) {
      const errText = await response.text();
      // å¦‚æœæ˜¯ 403ï¼Œè¯´æ˜ WAF è§„åˆ™è¿˜æ˜¯æ²¡é…å¥½ï¼›å¦‚æœæ˜¯ 404ï¼Œè¯´æ˜ URL é”™äº†
      throw new Error(`ä¸‹è½½å¤±è´¥ HTTP ${response.status} - ${errText.substring(0, 100)}`);
    }

    const arrayBuffer = await response.arrayBuffer();
    let buffer = Buffer.from(arrayBuffer);
    const originalSize = (buffer.length / 1024).toFixed(1);

    // ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šå¦‚æœå›¾ç‰‡è¶…è¿‡ 500KBï¼Œå°±è¿›è¡Œå‹ç¼©
    if (buffer.length > 500 * 1024) {
      // console.log(`ğŸ“‰ [Image] å›¾ç‰‡è¿‡å¤§ (${originalSize}KB), æ­£åœ¨å‹ç¼©...`);
      try {
        buffer = await sharp(buffer)
          .resize(1024, 1024, { fit: 'inside', withoutEnlargement: true }) // é™åˆ¶æœ€å¤§å°ºå¯¸
          .jpeg({ quality: 60, progressive: true }) // è½¬ä¸º JPEG 60% è´¨é‡ (AI è¶³å¤Ÿçœ‹æ¸…)
          .toBuffer();
      } catch (e) {
        console.warn('âš ï¸ [Image] å‹ç¼©å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸå›¾:', e.message);
      }
    }

    const finalSize = (buffer.length / 1024).toFixed(1);
    const base64 = buffer.toString('base64');
    
    console.log(`âœ… [Image] å¤„ç†å®Œæ¯•: ${cleanUrl.substring(cleanUrl.length - 20)} | ${originalSize}KB -> ${finalSize}KB`);
    return base64;

  } catch (error) {
    console.error(`âŒ [Image Error] ${error.message}`);
    return null; // è¿”å› null è§¦å‘åç»­çš„å…œåº•é€»è¾‘
  }
};

// ==========================================
// 2. æ ¸å¿ƒï¼šç»Ÿä¸€å¤„ç†å•ä¸ª Part çš„é€»è¾‘ (æå–å‡ºæ¥äº†)
// ==========================================
const processSinglePart = async (part) => {
  if (!part) return part;

  // 1. ä¾¦æµ‹ URL (å…¼å®¹ image å­—æ®µå’Œ inline_data é‡Œçš„ url)
  let targetUrl = null;
  const inlineData = part.inlineData?.data
  const imageUrl = part.image; // ğŸ‘ˆ ä¸“é—¨æ•è· routes/ai.js ä¼ æ¥çš„ { image: ... }

  if (typeof inlineData === 'string' && inlineData.startsWith('http')) targetUrl = inlineData;
  else if (typeof imageUrl === 'string' && imageUrl.startsWith('http')) targetUrl = imageUrl;

  // 2. å¦‚æœæ˜¯ URLï¼Œä¸‹è½½å¹¶è½¬æ¢
  if (targetUrl) {
    let mimeType = 'image/jpeg';
    if (targetUrl.toLowerCase().includes('.png')) mimeType = 'image/png';
    if (targetUrl.toLowerCase().includes('.webp')) mimeType = 'image/webp';
    
    const base64Data = await fetchImageAsBase64(targetUrl);

    if (base64Data) {
      // âœ… æˆåŠŸ: è½¬ä¸ºæ ‡å‡† Gemini æ ¼å¼
      return { 
        inlineData: { 
          mimeType: mimeType, 
          data: base64Data 
        } 
      };
    } else {
      // ğŸ›‘ å¤±è´¥: é™çº§ä¸ºæ–‡æœ¬ï¼Œé˜²æ­¢ 400 é”™è¯¯
      return { text: `[ç³»ç»Ÿæç¤º: å›¾ç‰‡ä¸‹è½½å¤±è´¥]` };
    }
  }

  // 3. å¦‚æœæœ¬æ¥å°±æ˜¯æ­£å¸¸çš„ Part (æ–‡æœ¬æˆ–å·²æœ‰Base64)ï¼ŒåŸæ ·è¿”å›
  return part;
};

// ==========================================
// 3. æ•°æ®æ¸…æ´— (å‡çº§ç‰ˆï¼šæ”¯æŒ History å’Œ Prompt ä¸¤ç§ç»“æ„)
// ==========================================
const prepareContentForGemini = async (contents) => {
  if (!contents) return [];
  // æ·±æ‹·è´
  const rawItems = JSON.parse(JSON.stringify(Array.isArray(contents) ? contents : [contents]));

  const processed = await Promise.all(rawItems.map(async (item) => {
    // ğŸ…°ï¸ æƒ…å†µ A: è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ Message å¯¹è±¡ (å¦‚ history)ï¼ŒåŒ…å« .parts æ•°ç»„
    if (item.parts && Array.isArray(item.parts)) {
      const newParts = await Promise.all(item.parts.map(p => processSinglePart(p)));
      return { ...item, parts: newParts };
    }
    // ğŸ…±ï¸ æƒ…å†µ B: è¿™æ˜¯ä¸€ä¸ªå•ç‹¬çš„ Part å¯¹è±¡ (å¦‚ prompt)ï¼Œç›´æ¥å°±æ˜¯ { image: ... } æˆ– { text: ... }
    else {
      return await processSinglePart(item);
    }
  }));

  return Array.isArray(contents) ? processed : processed[0];
};

// ... ä¸‹é¢æ˜¯å¸¸è§„å‡½æ•°ï¼Œä¿æŒä¸å˜ ...

function cleanJSONString(text) {
  if (!text) return '{}';
  let clean = text.replace(/```json|```/g, '').trim();
  const firstOpen = clean.indexOf('{');
  const lastClose = clean.lastIndexOf('}');
  if (firstOpen !== -1 && lastClose !== -1) clean = clean.substring(firstOpen, lastClose + 1);
  return clean;
}

function withTimeout(promise, ms) {
  return Promise.race([promise, new Promise((_, reject) => setTimeout(() => reject(new Error('TIMEOUT')), ms))]);
}

async function generateJSON(prompt, modelName = CONFIG.PRIMARY_MODEL) {
  let currentModel = modelName;
  let attempts = 0;
  const processedPrompt = await prepareContentForGemini(prompt);

  while (attempts <= 1) {
    attempts++;
    console.log(`ğŸ¤– [AI JSON] Model: ${currentModel}`);
    try {
      const response = await withTimeout(
        ai.models.generateContent({
          model: currentModel,
          contents: processedPrompt,
          config: { responseMimeType: 'application/json' }
        }),
        CONFIG.TIMEOUT_MS
      );
      const rawText = response.text || JSON.stringify(response);
      return JSON.parse(cleanJSONString(rawText));
    } catch (err) {
      console.error(`âš ï¸ [AI Error] ${currentModel}:`, err.message);
      if (err.message.includes('400')) throw err;
      if (currentModel !== CONFIG.FALLBACK_MODEL) {
        currentModel = CONFIG.FALLBACK_MODEL;
        attempts = 0;
        continue;
      }
      return { error: 'AI_BUSY', message: 'æœåŠ¡ç¹å¿™' };
    }
  }
}

async function generateStream(promptInput) {
  const currentModel = CONFIG.PRIMARY_MODEL;
  let formattedContents = typeof promptInput === 'string' ? [{ role: 'user', parts: [{ text: promptInput }] }] : promptInput;
  formattedContents = await prepareContentForGemini(formattedContents);

  try {
    return await ai.models.generateContentStream({ model: currentModel, contents: formattedContents });
  } catch (err) {
    try {
      return await ai.models.generateContentStream({ model: CONFIG.FALLBACK_MODEL, contents: formattedContents });
    } catch (e) { throw err; }
  }
}

async function* createAgentStream(params) {
  const currentModel = CONFIG.PRIMARY_MODEL;
  
  if (params.history) params.history = await prepareContentForGemini(params.history);
  params.prompt = await prepareContentForGemini(params.prompt);

  try {
    console.log(`ğŸŒŠ [Agent Stream] Start: ${currentModel}`);
    yield* _runAgentLoop(currentModel, params);
  } catch (err) {
    console.warn(`âš ï¸ [Agent Warning] ${currentModel} failed: ${err.message}`);
    if (currentModel !== CONFIG.FALLBACK_MODEL) {
      console.log(`ğŸ”„ [Agent Fallback] Switching to ${CONFIG.FALLBACK_MODEL}`);
      try {
        yield* _runAgentLoop(CONFIG.FALLBACK_MODEL, params);
      } catch (fallbackErr) { throw new Error(`Agent failed: ${fallbackErr.message}`); }
    } else { throw err; }
  }
}

async function* _runAgentLoop(modelName, { systemInstruction, history, prompt, toolsSchema, functionsMap }) {
  let finalTools = undefined;
  if (toolsSchema) {
    finalTools = Array.isArray(toolsSchema) && toolsSchema[0]?.functionDeclarations 
        ? toolsSchema 
        : [{ functionDeclarations: toolsSchema }];
  }

  const chat = ai.chats.create({
    model: modelName,
    history: history || [],
    config: { systemInstruction, tools: finalTools }
  });

  const resultStream = await chat.sendMessageStream({ message: prompt });
  let functionCallFound = false;
  const functionCallsToExecute = [];

  for await (const chunk of resultStream) {
    const calls = chunk.functionCalls;
    if (calls && calls.length > 0) {
      functionCallFound = true;
      functionCallsToExecute.push(...calls);
      continue;
    }
    if (!functionCallFound && chunk.text) yield chunk.text;
  }

  if (functionCallFound && functionCallsToExecute.length > 0) {
    const functionResponsesParts = [];
    for (const call of functionCallsToExecute) {
      const funcName = call.name;
      const args = call.args;
      let toolResult;
      if (functionsMap?.[funcName]) {
        try { toolResult = await functionsMap[funcName](args); } 
        catch (e) { toolResult = { error: e.message }; }
      } else { toolResult = { error: 'Function not found' }; }
      functionResponsesParts.push({ functionResponse: { name: funcName, response: { content: toolResult } } });
    }
    const result2 = await chat.sendMessageStream({ message: functionResponsesParts });
    for await (const chunk2 of result2) { if (chunk2.text) yield chunk2.text; }
  }
}

async function generateTitle(historyText) {
  try {
    const prompt = `ç”Ÿæˆä¸€ä¸ª5-10å­—çš„çº¯æ–‡æœ¬æ ‡é¢˜: ${historyText.substring(0, 500)}`;
    const result = await ai.models.generateContent(prompt);
    return result.text ? result.text.trim() : 'æ–°å¯¹è¯';
  } catch (e) { return 'æ–°å¯¹è¯'; }
}

export { generateJSON, generateStream, createAgentStream, generateTitle };
// utils/aiProvider.js
import { GoogleGenAI } from '@google/genai';

// 1. åŸºç¡€é…ç½®
if (!process.env.GEMINI_API_KEY) {
  throw new Error('âŒ [Fatal] ç¼ºå°‘ç¯å¢ƒå˜é‡ GEMINI_API_KEY');
}

// åˆå§‹åŒ–å®¢æˆ·ç«¯
const ai = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY
});

// ç”Ÿäº§çº§é…ç½®å¸¸é‡
const CONFIG = {
  // é¦–é€‰æ¨¡å‹
  PRIMARY_MODEL: 'gemini-3-flash-preview',
  // å¤‡èƒæ¨¡å‹
  FALLBACK_MODEL: 'gemini-2.0-flash-exp',
  // æœ€å¤§é‡è¯•æ¬¡æ•°
  MAX_RETRIES: 2,
  // è¶…æ—¶æ—¶é—´ (æ¯«ç§’)
  TIMEOUT_MS: 30000 
};

// ==========================================
// æ ¸å¿ƒä¿®å¤åŒºåŸŸï¼šå›¾ç‰‡é¢„å¤„ç†é€»è¾‘
// ==========================================

// è¾…åŠ©å‡½æ•°ï¼šç®€å•çš„åç¼€ååˆ¤æ–­ MimeType (ä¿®å¤ fix)
const getMimeType = (urlOrBase64) => {
  if (!urlOrBase64) return 'image/jpeg';
  if (urlOrBase64.startsWith('http')) {
      const lower = urlOrBase64.toLowerCase();
      if (lower.endsWith('.png')) return 'image/png';
      if (lower.endsWith('.webp')) return 'image/webp';
      if (lower.endsWith('.gif')) return 'image/gif';
  }
  return 'image/jpeg';
};

// è¾…åŠ©å‡½æ•°ï¼šå°† URL å›¾ç‰‡è½¬æ¢ä¸º Base64
const fetchImageAsBase64 = async (url) => {
  try {
    const response = await fetch(url);
    if (!response.ok) throw new Error(`Failed to fetch image: ${response.statusText}`);
    
    const arrayBuffer = await response.arrayBuffer();
    return Buffer.from(arrayBuffer).toString('base64');
  } catch (error) {
    console.error('Image conversion error:', error);
    return null; 
  }
};

/**
 * ğŸ”¥ æ ¸å¿ƒä¿®å¤å‡½æ•°ï¼šé€’å½’æ¸…æ´—å†…å®¹ï¼Œå…¼å®¹ URL å’Œ Base64
 */
const prepareContentForGemini = async (contents) => {
  if (!contents) return [];
  if (typeof contents === 'string') return contents;
  
  const isArray = Array.isArray(contents);
  const items = isArray ? contents : [contents];

  const processedItems = await Promise.all(items.map(async (item) => {
    // å¤„ç† { role, parts } ç»“æ„
    if (item.parts && Array.isArray(item.parts)) {
      const newParts = await Promise.all(item.parts.map(async (part) => {
        
        // case 1: è¿™æ˜¯ä¸€ä¸ª URL -> ä¸‹è½½è½¬ç 
        if (part.image && part.image.startsWith('http')) {
          const base64 = await fetchImageAsBase64(part.image);
          if (base64) {
            return {
              inline_data: {
                mime_type: getMimeType(part.image),
                data: base64
              }
            };
          }
          return { text: '[å›¾ç‰‡ä¸‹è½½å¤±è´¥]' };
        }

        // case 2: è¿™æ˜¯ä¸€ä¸ª Base64 -> ç›´æ¥ä½¿ç”¨
        if (part.image && !part.image.startsWith('http')) {
             return {
              inline_data: {
                mime_type: 'image/jpeg',
                data: part.image 
              }
            };
        }

        // case 3: å·²ç»æ˜¯ inline_data ä½†é‡Œé¢æ··äº† URL -> ä¿®å¤
        if (part.inline_data && part.inline_data.data && part.inline_data.data.startsWith('http')) {
            const base64 = await fetchImageAsBase64(part.inline_data.data);
            if (base64) {
                return {
                    inline_data: {
                        mime_type: getMimeType(part.inline_data.data),
                        data: base64
                    }
                };
            }
        }

        return part;
      }));
      return { ...item, parts: newParts };
    }
    return item;
  }));

  return isArray ? processedItems : processedItems[0];
};

// ==========================================
// é€šç”¨è¾…åŠ©å‡½æ•°
// ==========================================

function cleanJSONString(text) {
  if (!text) return '{}';
  let clean = text.replace(/```json|```/g, '').trim();
  const firstOpen = clean.indexOf('{');
  const lastClose = clean.lastIndexOf('}');
  if (firstOpen !== -1 && lastClose !== -1) {
    clean = clean.substring(firstOpen, lastClose + 1);
  }
  return clean;
}

function withTimeout(promise, ms) {
  return Promise.race([promise, new Promise((_, reject) => setTimeout(() => reject(new Error('TIMEOUT')), ms))]);
}

// ==========================================
// å¯¼å‡ºæ¥å£
// ==========================================

/**
 * æ ¸å¿ƒç”Ÿæˆå‡½æ•° (æ”¯æŒé‡è¯•ã€é™çº§ã€æ¸…æ´—)
 */
async function generateJSON(prompt, modelName = CONFIG.PRIMARY_MODEL) {
  let currentModel = modelName;
  let attempts = 0;

  // ğŸ”¥ ä¿®å¤ï¼šé¢„å¤„ç† prompt
  const processedPrompt = await prepareContentForGemini(prompt);

  while (attempts <= CONFIG.MAX_RETRIES) {
    attempts++;
    console.log(`ğŸ¤– [AI JSON] è¯·æ±‚æ¨¡å‹: ${currentModel} (å°è¯• ${attempts}/${CONFIG.MAX_RETRIES + 1})`);

    try {
      const response = await withTimeout(
        ai.models.generateContent({
          model: currentModel,
          contents: processedPrompt, // ä½¿ç”¨å¤„ç†åçš„å†…å®¹
          config: {
            responseMimeType: 'application/json'
          }
        }),
        CONFIG.TIMEOUT_MS
      );

      const rawText = response.text || JSON.stringify(response);
      const cleanedText = cleanJSONString(rawText);
      return JSON.parse(cleanedText);
    } catch (err) {
      console.error(`âš ï¸ [AI Error] æ¨¡å‹ ${currentModel} æŠ¥é”™:`, err.message);

      if (err.message.includes('404') || err.message.includes('not found') || err.message.includes('400')) {
        if (currentModel !== CONFIG.FALLBACK_MODEL) {
          console.warn(`ğŸ”„ [AI Fallback] åˆ‡æ¢å¤‡ç”¨æ¨¡å‹: ${CONFIG.FALLBACK_MODEL}`);
          currentModel = CONFIG.FALLBACK_MODEL;
          attempts = 0;
          continue;
        } else {
          // 400 é”™è¯¯é€šå¸¸æ˜¯å›¾ç‰‡æ ¼å¼é—®é¢˜
          throw new Error(`AI è¯·æ±‚å¤±è´¥ (400/404). è¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼. ${err.message}`);
        }
      }

      const isRetryable = err.message.includes('429') || err.message.includes('503') || err.message === 'TIMEOUT';
      if (isRetryable && attempts <= CONFIG.MAX_RETRIES) {
        const delay = attempts * 1000;
        console.log(`â³ [AI Retry] ${delay}ms åé‡è¯•...`);
        await new Promise((r) => setTimeout(r, delay));
        continue;
      }

      return {
        error: 'AI_GENERATION_FAILED',
        message: 'å¤§å¨æ­£åœ¨å¿™ï¼Œè¯·ç¨åå†è¯•',
        debug: err.message
      };
    }
  }
}

/**
 * ğŸŒŠ åŸºç¡€æµå¼ç”Ÿæˆ (æ—  Agent)
 */
async function generateStream(promptInput) {
  const currentModel = CONFIG.PRIMARY_MODEL;

  // ğŸ”¥ ä¿®å¤ï¼šé¢„å¤„ç†è¾“å…¥
  let formattedContents = typeof promptInput === 'string'
      ? [{ role: 'user', parts: [{ text: promptInput }] }]
      : promptInput;
      
  formattedContents = await prepareContentForGemini(formattedContents);

  try {
    console.log(`ğŸŒŠ [AI Stream] Attempting model: ${currentModel}`);

    const responseStream = await ai.models.generateContentStream({
      model: currentModel,
      contents: formattedContents
    });

    return responseStream;
  } catch (err) {
    console.error(`âš ï¸ [AI Stream Error] ${currentModel} failed:`, err.message);

    if (currentModel !== CONFIG.FALLBACK_MODEL) {
      console.warn(`ğŸ”„ [AI Stream Fallback] Switching to ${CONFIG.FALLBACK_MODEL}...`);
      try {
        const fallbackResponse = await ai.models.generateContentStream({
          model: CONFIG.FALLBACK_MODEL,
          contents: formattedContents
        });
        return fallbackResponse;
      } catch (fallbackErr) {
        throw new Error(`AI Stream All Failed: ${fallbackErr.message}`);
      }
    }
    throw err;
  }
}

/**
 * ğŸ§  Agent æµå¼ç”Ÿæˆå™¨ (å¯¹å¤–æš´éœ²)
 */
async function* createAgentStream(params) {
  const currentModel = CONFIG.PRIMARY_MODEL;

  // ğŸ”¥ ä¿®å¤ï¼šé¢„å¤„ç† history å’Œ prompt ä¸­çš„å›¾ç‰‡
  if (params.history && params.history.length > 0) {
    params.history = await prepareContentForGemini(params.history);
  }
  params.prompt = await prepareContentForGemini(params.prompt);

  try {
    console.log(`ğŸŒŠ [Agent Stream] Attempting with ${currentModel}...`);
    yield* _runAgentLoop(currentModel, params);
  } catch (err) {
    console.warn(`âš ï¸ [Agent Warning] ${currentModel} failed: ${err.message}`);

    if (currentModel !== CONFIG.FALLBACK_MODEL) {
      console.log(`ğŸ”„ [Agent Fallback] Switching to ${CONFIG.FALLBACK_MODEL}...`);
      try {
        yield* _runAgentLoop(CONFIG.FALLBACK_MODEL, params);
      } catch (fallbackErr) {
        console.error('âŒ [Agent Error] All models failed.');
        throw new Error(`Agent failed on both models: ${fallbackErr.message}`);
      }
    } else {
      throw err;
    }
  }
}

/**
 * ğŸ•µï¸ å†…éƒ¨æ ¸å¿ƒé€»è¾‘ï¼šAgent å¾ªç¯
 */
async function* _runAgentLoop(modelName, { systemInstruction, history, prompt, toolsSchema, functionsMap }) {
  let finalTools = undefined;

  if (toolsSchema) {
    const isAlreadyWrapped =
      Array.isArray(toolsSchema) && toolsSchema.length > 0 && toolsSchema[0].functionDeclarations;

    if (isAlreadyWrapped) {
      finalTools = toolsSchema;
    } else if (Array.isArray(toolsSchema)) {
      finalTools = [
        {
          functionDeclarations: toolsSchema
        }
      ];
    }
  }

  const chat = ai.chats.create({
    model: modelName,
    history: history || [],
    config: {
      systemInstruction: systemInstruction,
      tools: finalTools,
      maxOutputTokens: 8192
    }
  });

  const resultStream = await chat.sendMessageStream({
    message: prompt
  });

  let functionCallFound = false;
  const functionCallsToExecute = [];

  for await (const chunk of resultStream) {
    const calls = chunk.functionCalls;

    if (calls && calls.length > 0) {
      functionCallFound = true;
      functionCallsToExecute.push(...calls);
      continue;
    }

    if (!functionCallFound) {
      const text = chunk.text;
      if (text) yield text;
    }
  }

  if (functionCallFound && functionCallsToExecute.length > 0) {
    const functionResponsesParts = [];

    for (const call of functionCallsToExecute) {
      const funcName = call.name;
      const args = call.args;

      console.log(`ğŸ¤– [Agent Executor] Calling: ${funcName}`, args);

      let toolResult;
      if (functionsMap && functionsMap[funcName]) {
        try {
          toolResult = await functionsMap[funcName](args);
        } catch (e) {
          console.error(`Tool execution error (${funcName}):`, e);
          toolResult = {
            error: `Execution failed: ${e.message}`
          };
        }
      } else {
        toolResult = {
          error: `Function ${funcName} not found on server`
        };
      }

      functionResponsesParts.push({
        functionResponse: {
          name: funcName,
          response: {
            content: toolResult
          }
        }
      });
    }

    console.log(`ğŸ“¤ [Agent Output] Sending ${functionResponsesParts.length} tool results back...`);

    const result2 = await chat.sendMessageStream({
      message: functionResponsesParts
    });

    for await (const chunk2 of result2) {
      const text2 = chunk2.text;
      if (text2) yield text2;
    }
  }
}

/**
 * âš¡ï¸ ä¸“é—¨ç”¨äºç”Ÿæˆç®€çŸ­æ ‡é¢˜çš„å·¥å…·å‡½æ•°
 */
async function generateTitle(historyText) {
  try {
    const prompt = `
      åŸºäºä»¥ä¸‹å¯¹è¯ï¼Œç”Ÿæˆä¸€ä¸ªè¶…ç®€çŸ­çš„æ ‡é¢˜ï¼ˆ5-15å­—ï¼‰ã€‚
      è§„åˆ™ï¼šä¸è¦å¼•å·ï¼Œä¸è¦æ ‡ç‚¹ï¼Œåªè¦æ–‡å­—ã€‚
      
      å¯¹è¯å†…å®¹ï¼š
      ${historyText.substring(0, 1000)}
    `;

    const result = await ai.models.generateContent(prompt);

    // ä¿®å¤ï¼šç›´æ¥è¿”å›æ–‡æœ¬ï¼Œå› ä¸º prompt è¦æ±‚åªè¿”å›æ–‡å­—ï¼ŒJSON.parse å®¹æ˜“æŠ¥é”™
    return result.text ? result.text.trim() : 'æ–°å¯¹è¯';
  } catch (e) {
    console.error('æ ‡é¢˜ç”Ÿæˆå¤±è´¥:', e);
    return 'æ–°å¯¹è¯';
  }
}

export {
  generateJSON,
  generateStream,
  createAgentStream,
  generateTitle
};